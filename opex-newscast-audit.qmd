---
title: "Newscast Audit Report"
format: 
  typst: default
  html:
    page-layout: full
    theme: litera
params:
  data_path: ../newscast-audit.xlsx
jupyter: python3
execute:
  echo: false
  output: asis
---

<!--
How to use this report (editor-only note, not rendered):
- Install deps: pip install -r requirements.txt
- Place latest survey export at params$data_path (default ../newscast-audit.xlsx); fallback uses bundled example data
- Adjust COLUMN_MAPPING if export headers change
- Render: quarto render opex-newscast-audit.qmd (Typst/HTML). Only edit the Config section.
-->

```{python}
"""
Reusable helpers so non-Python users can follow the flow: config, loading, cleaning,
metrics, tables, and charts. Only edit the config block to change behavior.
"""
import os
import json
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.ticker import PercentFormatter
from IPython.display import HTML, Markdown, display
from pathlib import Path
import plotly.graph_objects as go

# --- Config (update here) ----------------------------------------------------
PARAMS = json.loads(os.environ.get("QUARTO_PARAMS", "{}"))
DATA_PRIMARY = Path(PARAMS.get("data_path", "../newscast-audit.xlsx"))
DATA_FALLBACKS = [
    Path("newscast-audit-example-data.xlsx"),
    Path("newscast-audit-example-data.xlsx.xlsx"),
]

COLUMN_MAPPING = {
    'Id': 'id',
    'Start time': 'start_time',
    'Completion time': 'completion_time',
    'Email': 'email',
    'Name': 'name',
    'Date of newscast:': 'newscast_date',
    'Which newscast are you auditing?': 'newscast',
    'Does each story create urgency with time relevance and active writing explaining why stories are being told right now? ': 'urgency_and_why_now',
    'Is a tease to streaming in at least every 30 minutes with specific content push for each show?': 'specific_streaming_tease',
    'Did we use streaming content and/or mobile shorts in this show?': 'streaming_or_mobile_shorts',
    'Are maps, timelines and supporting graphics used within 30 minutes for events and included as useful context in newscasts?': 'maps_graphics',
    'Is there a clearly defined weather story, supported by graphics or video?': 'weather_story_defined',
    'Does each weather hit focus on new/now/next?': 'new_now_next',
    'Does the story address the audience as "you," end with "Here\'s what you can do today"?': 'address_audience_call_to_action',
    'Does the story address the audience as “you,” end with "Here’s what you can do today”?': 'address_audience_call_to_action',
    'Are anchors shown three times per show on tight shots with name supers?': 'three_tight_anchor_shots_with_supers',
    'Did we specifically reference every piece of file or non-descript video?': 'reference_file_video',
    'Do anchors add local context to two or more stories and include one community-celebration story per hour?': 'local_context',
    'Additional comments below:': 'additional_comments'
}

METRIC_COLUMNS = [
    'urgency_and_why_now',
    'specific_streaming_tease',
    'streaming_or_mobile_shorts',
    'maps_graphics',
    'weather_story_defined',
    'new_now_next',
    'address_audience_call_to_action',
    'three_tight_anchor_shots_with_supers',
    'reference_file_video',
    'local_context'
]

THRESHOLDS = {"good": 80, "poor": 40}

# Order dayparts earliest to latest; unknowns fall to the end
NEWSCAST_ORDER = [
    '5 - 7 am',
    '7 - 9 am',
    'noon',
    '5 pm',
    '6 pm',
    '11 pm',
    'E +',
]

# Palette aligned to TEGNA site branding (deep navy / blue with orange accent)
PALETTE = {
    "primary": "#045ea8",  # TEGNA blue
    "secondary": "#00458c",  # deep blue
    "accent": "#f36f21",  # orange accent
    "alert": "#d64541",  # alert red (for low performance)
    "muted": "#6d6d6d",   # neutral gray
    "bg_soft": "#dbe6f1", # light blue-gray for grids
}

# Matplotlib style defaults
plt.rcParams.update({
    "figure.dpi": 140,
    "axes.titlesize": 16,
    "axes.labelsize": 13,
    "xtick.labelsize": 11,
    "ytick.labelsize": 11,
    "legend.fontsize": 11,
    "axes.edgecolor": PALETTE["bg_soft"],
    "axes.grid": False,
})

# HTML table styling (keeps PDF/HTML tables visually similar)
display(Markdown("""
<style>
table {
  border-collapse: collapse;
  border: 1px solid #dbe6f1;
}
table th, table td {
  padding: 0.45rem 0.6rem;
  border: 1px solid #dbe6f1;
}
table th {
  background: #f7f9fc;
  font-weight: 700;
}
table tr:nth-child(even) td {
  background: #fbfdff;
}
</style>
"""))

# --- Helpers -----------------------------------------------------------------

def detect_output():
    """Detect rendering target to keep PDF/HTML-specific behavior simple."""
    fmt = os.environ.get("QUARTO_OUTPUT_FORMAT", "").lower()
    render = os.environ.get("QUARTO_RENDER_FORMAT", "").lower()
    combined = f"{fmt},{render}"
    is_pdf = any(t in combined for t in ("pdf", "latex"))
    is_html = ("html" in combined) or (not combined and not is_pdf) or ("typst" not in combined and not is_pdf)
    return {
        "is_pdf": is_pdf,
        "is_html": is_html,
    }


def choose_data_path():
    """Pick the primary Excel file or fall back to bundled example data."""
    if DATA_PRIMARY.exists():
        return DATA_PRIMARY, f"Using data file: **{DATA_PRIMARY.name}**"
    for candidate in DATA_FALLBACKS:
        if candidate.exists():
            return candidate, "Using example data"
    raise FileNotFoundError(f"Could not find {DATA_PRIMARY} or any fallback: {DATA_FALLBACKS}")


def normalize_newscast(value):
    """Map noisy free-text newscast names into consistent buckets used for sorting."""
    if pd.isna(value):
        return None
    v = str(value).strip().lower()

    if 'evening+' in v or v.startswith('evening') or 'e+' in v:
        return 'E +'
    if '11' in v and ('pm' in v or 'p.m' in v or 'p' in v):
        return '11 pm'
    if '6' in v and ('pm' in v or 'p.m' in v):
        return '6 pm'
    if ('5:30' in v or '5:30pm' in v) and ('pm' in v or 'p.m' in v):
        return '5 pm'
    if ('5' in v) and ('pm' in v):
        return '5 pm'
    if 'noon' in v or '12' in v:
        return 'noon'

    # morning checks (ranges first to avoid misclassification)
    if '5' in v and '7' in v and 'am' in v:
        return '5 - 7 am'
    if '7' in v and '9' in v and 'am' in v:
        return '7 - 9 am'
    if ('5' in v) and ('am' in v or 'a-' in v or 'a ' in v):
        return '5 - 7 am'
    if ('7' in v) and ('am' in v or 'a-' in v or 'a ' in v):
        return '7 - 9 am'

    return str(value).strip()


def convert_to_numeric(v):
    """Convert survey responses into 1/0/NA, accepting common yes/no spellings."""
    if pd.isna(v):
        return pd.NA
    s = str(v).strip().lower()
    if s in ('yes', 'y', 'true', '1'):
        return 1
    if s in ('no', 'n', 'false', '0'):
        return 0
    if s in ('n/a', 'na', 'none', ''):
        return pd.NA
    try:
        num = float(s)
        if num == 1:
            return 1
        if num == 0:
            return 0
    except Exception:
        pass
    return pd.NA


def standardize_columns(df):
    """Rename source columns to clean snake_case names the rest of the report expects."""
    df = df.rename(columns={k: v for k, v in COLUMN_MAPPING.items() if k in df.columns})
    for col in df.columns:
        col_lower = str(col).lower()
        if ('what you can do' in col_lower) or ('address the audience' in col_lower) or ("here" in col_lower and "you" in col_lower):
            df = df.rename(columns={col: 'address_audience_call_to_action'})
            break
    return df


def clean_data(df):
    """Apply column standardization, parse dates, coerce metrics to numeric, drop empty rows."""
    df = standardize_columns(df)
    if 'newscast' in df.columns:
        df['newscast_normalized'] = df['newscast'].apply(normalize_newscast)
    else:
        df['newscast_normalized'] = None

    df['newscast_date_parsed'] = pd.to_datetime(df.get('newscast_date'), errors='coerce') if 'newscast_date' in df.columns else pd.NaT

    present_metrics = [c for c in METRIC_COLUMNS if c in df.columns]
    for col in present_metrics:
        df[col] = df[col].apply(convert_to_numeric)
        try:
            df[col] = df[col].astype('Int64')
        except Exception:
            pass
    dropped_empty = 0
    if present_metrics:
        mask = df[present_metrics].notna().any(axis=1)
        dropped_empty = (~mask).sum()
        df = df[mask].reset_index(drop=True)

    return df, present_metrics, dropped_empty


def question_labels(columns):
    """Human-friendly labels for chart/table display."""
    return [c.replace('_', ' ').title() for c in columns]


def sort_newscast_series(s):
    """Sort a series of newscast names by the predefined NEWSCAST_ORDER."""
    order_lookup = {name: idx for idx, name in enumerate(NEWSCAST_ORDER)}
    return s.sort_values(key=lambda x: x.map(lambda v: order_lookup.get(v, len(order_lookup)+1)))

def sort_newscast_table(df, column_name='Newscast'):
    """Return df sorted by newscast order, pushing missing/unknown to the end."""
    order = NEWSCAST_ORDER + ['Unspecified']
    temp = df.copy()
    temp[column_name] = temp[column_name].fillna('Unspecified')
    temp[column_name] = pd.Categorical(temp[column_name], categories=order, ordered=True)
    return temp.sort_values(by=column_name).reset_index(drop=True)


def render_table(title, df):
    display(Markdown(f"### {title}"))
    display(Markdown(df.to_markdown(index=False, tablefmt="github")))


def color_for(percent):
    """Pick a palette color based on thresholded performance bands."""
    if pd.isna(percent):
        return PALETTE["muted"]
    if percent >= THRESHOLDS['good']:
        return PALETTE["primary"]
    if percent <= THRESHOLDS['poor']:
        return PALETTE["alert"]
    return PALETTE["accent"]


def build_yes_percent_table(df, metric_columns):
    """Return a tidy table of Yes% per question for a given DataFrame slice."""
    summary = df[metric_columns].mean(skipna=True) * 100
    summary = summary.round(0).where(summary.notna(), pd.NA).astype("Int64")
    out = summary.rename('Yes %').reset_index().rename(columns={'index': 'Question'})
    out['Question'] = question_labels(out['Question'])
    return out


def with_week_start(df, date_col='newscast_date_parsed'):
    """Return df with a computed Monday week_start column or None if no dates."""
    if date_col not in df.columns or df[date_col].isna().all():
        return None
    out = df.dropna(subset=[date_col]).copy()
    out['week_start'] = out[date_col] - pd.to_timedelta(out[date_col].dt.weekday, unit='D')
    return out


def plot_overall(overall_pct, n_records):
    """Bar chart of average Yes% across all responses."""
    labels = question_labels(overall_pct.index)
    values = overall_pct.round(0).fillna(0).astype(int)
    colors = [color_for(v) for v in values]

    fig, ax = plt.subplots(figsize=(16, max(8, len(labels) * 0.5)))
    bars = ax.bar(labels, values, color=colors)
    for bar, val in zip(bars, values):
        ax.text(bar.get_x() + bar.get_width()/2, val + 1, f"{val}%", ha='center', va='bottom', fontsize=11, color=PALETTE["primary"])

    ax.set_ylim(0, 110)
    ax.set_ylabel('Percent yes')
    ax.set_title(f"Overall Audit Metrics (n={n_records})")
    ax.yaxis.set_major_formatter(PercentFormatter(xmax=100))
    plt.xticks(rotation=35, ha='right')
    fig.subplots_adjust(bottom=0.25)
    plt.tight_layout()
    plt.show()


def plot_per_newscast(df, metric_columns):
    """Horizontal bars by question for each newscast bucket."""
    if 'newscast_normalized' not in df.columns:
        display(Markdown("No `newscast` column found."))
        return
    # sort by defined order; anything unknown goes to the end
    order_lookup = {name: idx for idx, name in enumerate(NEWSCAST_ORDER)}
    unique_newscasts = sorted(
        [nc for nc in df['newscast_normalized'].dropna().unique()],
        key=lambda x: order_lookup.get(x, len(order_lookup) + 1)
    )
    for nc in unique_newscasts:
        sub = df[df['newscast_normalized'] == nc]
        if sub.empty:
            continue
        sub_mean = (sub[metric_columns].mean(skipna=True) * 100).round(0)
        labels = question_labels(sub_mean.index)
        values = sub_mean.fillna(0).astype(int)
        colors = [color_for(v) for v in values]

        fig, ax = plt.subplots(figsize=(16, max(6, len(labels) * 0.45)))
        bars = ax.barh(labels, values, color=colors)
        for bar, val in zip(bars, values):
            ax.text(val + 1, bar.get_y() + bar.get_height()/2, f"{val}%", va='center', fontsize=11, color=PALETTE["primary"])

        ax.set_xlim(0, 110)
        ax.set_xlabel('Percent yes')
        ax.set_title(f"{nc} — Audit Metrics (n={len(sub)})")
        ax.xaxis.set_major_formatter(PercentFormatter(xmax=100))
        plt.tight_layout()
        plt.show()


def plot_weekly(df, metric_columns):
    """Line chart of weekly overall Yes% with fixed y-range for comparability."""
    df_week = with_week_start(df)
    if df_week is None:
        display(Markdown("No parsable `newscast_date` values found to compute timeline."))
        return

    # single aggregate line: average of all metrics per row, then weekly mean
    df_week['overall_mean'] = df_week[metric_columns].mean(axis=1)
    weekly_agg = df_week.groupby('week_start')['overall_mean'].mean() * 100

    if weekly_agg.empty:
        display(Markdown("No data available for weekly aggregation."))
        return

    fig, ax = plt.subplots(figsize=(16, 7))
    ax.plot(
        weekly_agg.index,
        weekly_agg,
        marker='o',
        linewidth=2.2,
        markersize=9,
        color=PALETTE["primary"],
        label="Weekly percent",
    )
    # label last point
    ax.text(
        weekly_agg.index[-1],
        weekly_agg.iloc[-1] + 2,
        f"{weekly_agg.iloc[-1]:.0f}%",
        ha='center',
        va='bottom',
        color=PALETTE["primary"],
        fontsize=10,
    )

    ax.set_xlabel('Week Starting (Monday)')
    ax.set_ylabel('Percent (%)')
    ax.set_title('Overall Percent Yes Over Time (Weekly)')
    ax.yaxis.set_major_formatter(PercentFormatter(xmax=100))
    # fixed y-limits for readability
    ax.set_ylim(40, 100)
    ax.legend(loc='best', frameon=False)
    ax.set_xticks(weekly_agg.index)
    ax.set_xticklabels([d.strftime('%m/%d') for d in weekly_agg.index], rotation=45, ha='right')
    fig.subplots_adjust(bottom=0.18)
    plt.tight_layout()
    plt.show()


# --- Interactive weekly line helpers -----------------------------------------

def weekly_percent_series(df, metric_columns, newscast=None, question=None):
    """Compute weekly average percent Yes with optional newscast/question filters."""
    data = df.copy()
    if newscast == "__unspecified":
        data = data[data['newscast_normalized'].isna()]
    elif newscast is not None:
        data = data[data['newscast_normalized'] == newscast]
    if data.empty:
        return None

    metrics = metric_columns
    if question is not None:
        metrics = [question] if question in metric_columns else []
    if not metrics:
        return None

    data = with_week_start(data)
    if data is None or data.empty:
        return None

    data['overall_mean'] = data[metrics].mean(axis=1)
    weekly_agg = data.groupby('week_start')['overall_mean'].mean()
    if weekly_agg.empty:
        return None

    return {
        "dates": weekly_agg.index,
        "pct": weekly_agg * 100,
    }


def plotly_weekly_line_combined(df, metric_columns):
    """Interactive weekly line chart dropdown: filter by newscast or specific question."""
    if 'newscast_normalized' not in df.columns:
        display(Markdown("No `newscast` column found."))
        return
    nc_series = df['newscast_normalized'].dropna()
    nc_options = sort_newscast_series(nc_series).unique().tolist() if not nc_series.empty else []
    option_defs = []
    # Overall (all newscasts, all questions)
    option_defs.append(("All newscasts | All questions", {"newscast": None, "question": None}))
    # Newscast filters (all questions)
    for nc in nc_options:
        option_defs.append((f"Newscast: {nc}", {"newscast": ('__unspecified' if nc == 'Unspecified' else nc), "question": None}))
    # Question filters (all newscasts)
    for q in metric_columns:
        option_defs.append((f"Question: {q.replace('_',' ').title()}", {"newscast": None, "question": q}))

    traces = []
    option_slices = []

    for label, filters in option_defs:
        series = weekly_percent_series(df, metric_columns, newscast=filters["newscast"], question=filters["question"])
        if not series:
            continue
        color = PALETTE["primary"]
        start_idx = len(traces)
        traces.append(
            go.Scatter(
                x=series["dates"],
                y=series["pct"],
                mode="lines+markers",
                marker=dict(size=9, color=color),
                line=dict(width=2, color=color),
                name="Weekly percent",
                visible=False,
            )
        )
        option_slices.append((label, start_idx, len(traces)))

    if not traces:
        display(Markdown("No data to plot for the combined weekly chart."))
        return

    fig = go.Figure(traces)

    # Build buttons after all traces exist so visibility masks cover full length
    buttons = []
    total_traces = len(traces)
    for label, start_idx, end_idx in option_slices:
        vis = [False] * total_traces
        for i in range(start_idx, end_idx):
            vis[i] = True
        buttons.append(dict(label=label, method="update", args=[{"visible": vis}]))

    fig.update_layout(
        title="Overall Percent Yes Over Time (Weekly) — filter by newscast and question",
        xaxis_title="Week starting (Monday)",
        yaxis_title="Percent (%)",
        yaxis=dict(range=[40, 100]),
        font=dict(size=14),
        updatemenus=[dict(buttons=buttons, direction="down", showactive=True, x=0, y=1.2, xanchor="left", yanchor="bottom")],
        margin=dict(t=60, b=60, l=60, r=20),
        legend=dict(orientation="h", y=-0.2),
    )
    # Show first option by default
    if option_slices:
        for i in range(total_traces):
            fig.data[i].visible = False
        first_start, first_end = option_slices[0][1], option_slices[0][2]
        for i in range(first_start, first_end):
            fig.data[i].visible = True

    # Render inline to avoid renderer issues in some environments
    html = fig.to_html(include_plotlyjs="cdn", full_html=False)
    display(HTML(html))


# --- Excel export helpers -----------------------------------------------------

def build_weekly_line_table(df, metric_columns):
    """Build a wide weekly table for Excel with overall/newscast/question series."""
    frames = []

    base_series = weekly_percent_series(df, metric_columns)
    if base_series:
        base_df = pd.DataFrame({
            'Week starting': pd.to_datetime(base_series["dates"]),
            'All newscasts | All questions': pd.to_numeric(base_series["pct"]).round(1),
        })
        frames.append(base_df)

    if 'newscast_normalized' in df.columns:
        nc_series = df['newscast_normalized'].dropna()
        nc_options = sort_newscast_series(nc_series).unique().tolist() if not nc_series.empty else []
        if df['newscast_normalized'].isna().any():
            nc_options.append('__unspecified')
        for nc in nc_options:
            label = "Newscast: Unspecified" if nc == '__unspecified' else f"Newscast: {nc}"
            series = weekly_percent_series(df, metric_columns, newscast=nc)
            if not series:
                continue
            frames.append(pd.DataFrame({
                'Week starting': pd.to_datetime(series["dates"]),
                label: pd.to_numeric(series["pct"]).round(1),
            }))

    for q in metric_columns:
        series = weekly_percent_series(df, metric_columns, question=q)
        if not series:
            continue
        label = f"Question: {q.replace('_',' ').title()}"
        frames.append(pd.DataFrame({
            'Week starting': pd.to_datetime(series["dates"]),
            label: pd.to_numeric(series["pct"]).round(1),
        }))

    if not frames:
        return pd.DataFrame()

    weekly_df = frames[0]
    for frame in frames[1:]:
        weekly_df = weekly_df.merge(frame, on='Week starting', how='outer')

    weekly_df = weekly_df.sort_values('Week starting')
    return weekly_df


def export_excel_workbook(df, metric_columns, overall_df, recent_df, volume_df, weekly_chart_df, output_path="newscast-audit-export.xlsx"):
    """Write normalized data and tables to disk (data-only, no Excel chart)."""
    if df.empty:
        return None

    output_path = Path(output_path)
    with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="Normalized Data", index=False)

        if overall_df is not None and not overall_df.empty:
            overall_df.to_excel(writer, sheet_name="Overall Metrics", index=False)

        if recent_df is not None and not recent_df.empty:
            recent_df.to_excel(writer, sheet_name="Recent Week Metrics", index=False)

        if volume_df is not None and not volume_df.empty:
            volume_df.to_excel(writer, sheet_name="Responses by Newscast", index=False)

        if weekly_chart_df is not None and not weekly_chart_df.empty:
            weekly_chart_df.to_excel(writer, sheet_name="Weekly Line Data", index=False)

    return output_path
```

```{python}
# Load and clean data

data_path, source_msg = choose_data_path()
display(Markdown(f"**{source_msg}**"))

df_raw = pd.read_excel(data_path)
df, metric_columns, dropped_empty = clean_data(df_raw.copy())

record_count = len(df)
missing_newscast = df['newscast_normalized'].isna().sum() if 'newscast_normalized' in df.columns else 0

summary_parts = [
    f"**Rows:** {record_count}",
    f"**Metrics:** {len(metric_columns)}",
    f"**Missing newscast:** {missing_newscast}",
]
if dropped_empty:
    summary_parts.append(f"**Dropped empty responses:** {dropped_empty}")
summary_info = " | ".join(summary_parts)

overall_df = None
recent_df = None
volume = None
```

---

```{python}
# Summaries: overall, recent week, volume, top/bottom, missingness

if metric_columns:
    overall_df = build_yes_percent_table(df, metric_columns)
    render_table('Overall Metrics', overall_df)

    # Recent week (starting Monday of latest date)
    if 'newscast_date_parsed' in df.columns and df['newscast_date_parsed'].notna().any():
        max_date = df['newscast_date_parsed'].max()
        week_start = max_date - pd.Timedelta(days=max_date.weekday())
        recent = df[df['newscast_date_parsed'] >= week_start]
        if not recent.empty:
            recent_df = build_yes_percent_table(recent, metric_columns)
            render_table(f"Current Week Metrics (Starting {week_start.strftime('%B %d, %Y')}, n={len(recent)})", recent_df)
        else:
            display(Markdown("No recent-week data found."))
    else:
        display(Markdown("No parsable `newscast_date` values found to compute recent week."))

    # Volume by newscast
    if 'newscast_normalized' in df.columns:
        volume = df['newscast_normalized'].value_counts(dropna=False).rename_axis('Newscast').reset_index(name='Responses')
        volume = sort_newscast_table(volume, 'Newscast')
        render_table('Responses by Newscast', volume)

else:
    display(Markdown("No metric columns found after cleaning."))
```

---

```{python}
# Charts

if metric_columns:
    # Interactive Plotly charts (HTML only)
    output = detect_output()
    if output["is_html"]:
        plotly_weekly_line_combined(df, metric_columns)

    plot_overall(df[metric_columns].mean(skipna=True) * 100, record_count)
    plot_per_newscast(df, metric_columns)
    plot_weekly(df, metric_columns)

    # Excel export with normalized data and tables (no Excel chart)
    weekly_chart_df = build_weekly_line_table(df, metric_columns)
    excel_path = export_excel_workbook(
        df,
        metric_columns,
        overall_df,
        recent_df,
        volume,
        weekly_chart_df,
        output_path="newscast-audit-export.xlsx",
    )
    if excel_path:
        display(Markdown(f"Saved Excel export: **{excel_path.name}** (data-only; no Excel chart)."))
else:
    display(Markdown("No metric columns found after cleaning."))

# Summary at bottom
display(Markdown("**" + source_msg + "**"))
display(Markdown(summary_info))
```
